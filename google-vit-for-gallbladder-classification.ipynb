{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9552012,"sourceType":"datasetVersion","datasetId":5820056}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Exploring Dataset\n","metadata":{}},{"cell_type":"code","source":"import os\nfrom PIL import Image\nimport numpy as np\nimport matplotlib.pyplot as plt\n    \n# Path to your image directory\n# image_directory='/kaggle/input/gallbladder/Gallblader Diseases Dataset/1Gallstones'\n\n# Initialize variables to collect data\n\n# Function to explore images\ndef explore_images(image_directory):\n    image_sizes = []\n    image_channels = []\n    pixel_values = []\n\n#     print(image_directory)\n    image_paths = [os.path.join(image_directory, fname) for fname in os.listdir(image_directory) if fname.endswith(('jpg', 'png', 'jpeg'))]\n#     print(image_paths)\n    for image_path in image_paths:\n        # Open the image\n        image = Image.open(image_path)\n        \n        # Get image size (width, height)\n        image_sizes.append(image.size)\n        \n        # Get image color channels (1 for grayscale, 3 for RGB)\n        image_channels.append(len(image.getbands()))  # 'RGB' gives 3 channels, 'L' gives 1\n        \n        # Convert image to numpy array for statistical analysis\n        image_array = np.array(image)\n        pixel_values.append(image_array)\n\n    # Return the collected statistics\n    image_sizes, image_channels, pixel_values\n\n\n    # Find unique image sizes\n    unique_image_sizes = set(image_sizes)  # Using set to get unique sizes\n\n    # Print the number of unique image sizes\n    print(f\"Number of unique image sizes: {len(unique_image_sizes)}\")\n    print(f\"Unique image sizes: {unique_image_sizes}\")\n# # Statistics about image sizes\n    image_sizes = np.array(image_sizes)\n    image_channels = np.array(image_channels)\n\n    # Print basic statistics about image sizes\n    print(\"Image Dimensions (width x height):\")\n    print(f\"Minimum size: {image_sizes.min(axis=0)}\")\n    print(f\"Maximum size: {image_sizes.max(axis=0)}\")\n    print(f\"Average size: {image_sizes.mean(axis=0)}\")\n\n    # Check if images are grayscale or RGB\n    print(f\"\\nNumber of Grayscale images: {np.sum(image_channels == 1)}\")\n    print(f\"Number of RGB images: {np.sum(image_channels == 3)}\")\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-11-07T06:35:14.942741Z","iopub.execute_input":"2024-11-07T06:35:14.943294Z","iopub.status.idle":"2024-11-07T06:35:14.959338Z","shell.execute_reply.started":"2024-11-07T06:35:14.943258Z","shell.execute_reply":"2024-11-07T06:35:14.958373Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import os\nroot_directory = '/kaggle/input/gallbladder/Gallblader Diseases Dataset'  # Update to your dataset path\ndirectory=os.listdir('/kaggle/input/gallbladder/Gallblader Diseases Dataset')\n# print(directory)\nfor d in directory:\n    print(d)\n    explore_images(os.path.join(root_directory,d))\n    print('\\n')\n    print('**************************************************')","metadata":{"execution":{"iopub.status.busy":"2024-11-07T06:35:14.961182Z","iopub.execute_input":"2024-11-07T06:35:14.961463Z","iopub.status.idle":"2024-11-07T07:03:23.109604Z","shell.execute_reply.started":"2024-11-07T06:35:14.961433Z","shell.execute_reply":"2024-11-07T07:03:23.108402Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"8Carcinoma\nNumber of unique image sizes: 2\nUnique image sizes: {(2400, 1800), (1200, 900)}\nImage Dimensions (width x height):\nMinimum size: [1200  900]\nMaximum size: [2400 1800]\nAverage size: [1200.75471698  900.56603774]\n\nNumber of Grayscale images: 0\nNumber of RGB images: 1590\n\n\n**************************************************\n6Polyps and cholesterol crystals\nNumber of unique image sizes: 2\nUnique image sizes: {(900, 1200), (1200, 900)}\nImage Dimensions (width x height):\nMinimum size: [900 900]\nMaximum size: [1200 1200]\nAverage size: [1193.52941176  906.47058824]\n\nNumber of Grayscale images: 0\nNumber of RGB images: 1020\n\n\n**************************************************\n3cholecystitis\nNumber of unique image sizes: 3\nUnique image sizes: {(2400, 1800), (900, 1200), (1200, 900)}\nImage Dimensions (width x height):\nMinimum size: [900 900]\nMaximum size: [2400 1800]\nAverage size: [1194.76439791  907.06806283]\n\nNumber of Grayscale images: 0\nNumber of RGB images: 1146\n\n\n**************************************************\n9Various causes of gallbladder wall thickening\nNumber of unique image sizes: 1\nUnique image sizes: {(1200, 900)}\nImage Dimensions (width x height):\nMinimum size: [1200  900]\nMaximum size: [1200  900]\nAverage size: [1200.  900.]\n\nNumber of Grayscale images: 0\nNumber of RGB images: 990\n\n\n**************************************************\n7Adenomyomatosis\nNumber of unique image sizes: 1\nUnique image sizes: {(1200, 900)}\nImage Dimensions (width x height):\nMinimum size: [1200  900]\nMaximum size: [1200  900]\nAverage size: [1200.  900.]\n\nNumber of Grayscale images: 0\nNumber of RGB images: 1164\n\n\n**************************************************\n5Perforation\nNumber of unique image sizes: 2\nUnique image sizes: {(1170, 876), (1200, 900)}\nImage Dimensions (width x height):\nMinimum size: [1170  876]\nMaximum size: [1200  900]\nAverage size: [1199.97175141  899.97740113]\n\nNumber of Grayscale images: 0\nNumber of RGB images: 1062\n\n\n**************************************************\n1Gallstones\nNumber of unique image sizes: 1\nUnique image sizes: {(1200, 900)}\nImage Dimensions (width x height):\nMinimum size: [1200  900]\nMaximum size: [1200  900]\nAverage size: [1200.  900.]\n\nNumber of Grayscale images: 0\nNumber of RGB images: 1326\n\n\n**************************************************\n2Abdomen and retroperitoneum\nNumber of unique image sizes: 1\nUnique image sizes: {(1200, 900)}\nImage Dimensions (width x height):\nMinimum size: [1200  900]\nMaximum size: [1200  900]\nAverage size: [1200.  900.]\n\nNumber of Grayscale images: 0\nNumber of RGB images: 1170\n\n\n**************************************************\n4Membranous and gangrenous cholecystitis\nNumber of unique image sizes: 2\nUnique image sizes: {(1170, 876), (1200, 900)}\nImage Dimensions (width x height):\nMinimum size: [1170  876]\nMaximum size: [1200  900]\nAverage size: [1199.90196078  899.92156863]\n\nNumber of Grayscale images: 0\nNumber of RGB images: 1224\n\n\n**************************************************\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#  Google Vit","metadata":{}},{"cell_type":"code","source":"pip install tensorflow tensorflow-hub tensorflow-datasets","metadata":{"execution":{"iopub.status.busy":"2024-11-07T08:14:00.920354Z","iopub.execute_input":"2024-11-07T08:14:00.920669Z","iopub.status.idle":"2024-11-07T08:14:14.109290Z","shell.execute_reply.started":"2024-11-07T08:14:00.920635Z","shell.execute_reply":"2024-11-07T08:14:14.108191Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: tensorflow in /opt/conda/lib/python3.10/site-packages (2.16.1)\nRequirement already satisfied: tensorflow-hub in /opt/conda/lib/python3.10/site-packages (0.16.1)\nRequirement already satisfied: tensorflow-datasets in /opt/conda/lib/python3.10/site-packages (4.9.6)\nRequirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.6.3)\nRequirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (24.3.25)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.5.4)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: h5py>=3.10.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.11.0)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (18.1.1)\nRequirement already satisfied: ml-dtypes~=0.3.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.3.2)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.3.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow) (21.3)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.20.3)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.32.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow) (70.0.0)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.4.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.12.2)\nRequirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.62.2)\nRequirement already satisfied: tensorboard<2.17,>=2.16 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.16.2)\nRequirement already satisfied: keras>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.3.3)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.37.0)\nRequirement already satisfied: numpy<2.0.0,>=1.23.5 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.26.4)\nRequirement already satisfied: tf-keras>=2.14.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow-hub) (2.16.0)\nRequirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets) (8.1.7)\nRequirement already satisfied: dm-tree in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets) (0.1.8)\nRequirement already satisfied: immutabledict in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets) (4.2.0)\nRequirement already satisfied: promise in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets) (2.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets) (5.9.3)\nRequirement already satisfied: pyarrow in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets) (16.1.0)\nRequirement already satisfied: simple-parsing in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets) (0.1.5)\nRequirement already satisfied: tensorflow-metadata in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets) (0.14.0)\nRequirement already satisfied: toml in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets) (0.10.2)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets) (4.66.4)\nRequirement already satisfied: array-record>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets) (0.5.1)\nRequirement already satisfied: etils>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from etils[enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets) (1.7.0)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from etils[enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets) (2024.6.1)\nRequirement already satisfied: importlib_resources in /opt/conda/lib/python3.10/site-packages (from etils[enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets) (6.4.0)\nRequirement already satisfied: zipp in /opt/conda/lib/python3.10/site-packages (from etils[enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets) (3.19.2)\nRequirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow) (13.7.1)\nRequirement already satisfied: namex in /opt/conda/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow) (0.0.8)\nRequirement already satisfied: optree in /opt/conda/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow) (0.11.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.6)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.0.4)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow) (3.1.2)\nRequirement already satisfied: docstring-parser~=0.15 in /opt/conda/lib/python3.10/site-packages (from simple-parsing->tensorflow-datasets) (0.16)\nRequirement already satisfied: googleapis-common-protos in /opt/conda/lib/python3.10/site-packages (from tensorflow-metadata->tensorflow-datasets) (1.63.1)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.5)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras>=3.0.0->tensorflow) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras>=3.0.0->tensorflow) (2.18.0)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow) (0.1.2)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install pillow","metadata":{"execution":{"iopub.status.busy":"2024-11-07T08:14:19.456708Z","iopub.execute_input":"2024-11-07T08:14:19.457135Z","iopub.status.idle":"2024-11-07T08:14:30.852791Z","shell.execute_reply.started":"2024-11-07T08:14:19.457075Z","shell.execute_reply":"2024-11-07T08:14:30.851572Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (10.3.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install transformers torch torchvision\n","metadata":{"execution":{"iopub.status.busy":"2024-11-07T09:37:19.602557Z","iopub.execute_input":"2024-11-07T09:37:19.602931Z","iopub.status.idle":"2024-11-07T09:37:31.902699Z","shell.execute_reply.started":"2024-11-07T09:37:19.602890Z","shell.execute_reply":"2024-11-07T09:37:31.901551Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.45.1)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.4.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (0.19.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.25.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.0)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.6.1)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision) (10.3.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data import Dataset, DataLoader\nimport torch\nfrom transformers import AutoImageProcessor, AutoModelForImageClassification\n\n# Load processor and model\nmodel_name = \"google/vit-base-patch16-384\"\nprocessor = AutoImageProcessor.from_pretrained(model_name)\nmodel = AutoModelForImageClassification.from_pretrained(model_name)\n\n# Custom Dataset Class\nclass CustomImageDataset(Dataset):\n    def __init__(self, image_paths, labels, processor):\n        self.image_paths = image_paths\n        self.labels = labels\n        self.processor = processor\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, idx):\n        image_path = self.image_paths[idx]\n        image = Image.open(image_path).convert(\"RGB\")\n        inputs = self.processor(images=image, return_tensors=\"pt\")\n        image_tensor = inputs['pixel_values'].squeeze(0)\n        label = self.labels[idx]\n        return image_tensor, label\n\n# Load image paths and labels\nroot_directory = \"/kaggle/input/gallbladder/Gallblader Diseases Dataset\"\nclass_names = sorted(os.listdir(root_directory))\nimage_paths = []\nlabels = []\n\nfor label, class_name in enumerate(class_names):\n    class_dir = os.path.join(root_directory, class_name)\n    for img_name in os.listdir(class_dir):\n        image_paths.append(os.path.join(class_dir, img_name))\n        labels.append(label)\n\n# Stratified split for train and test sets\ntrain_paths, test_paths, train_labels, test_labels = train_test_split(\n    image_paths, labels, test_size=0.2, stratify=labels, random_state=42\n)\n\n# Create train and test datasets\ntrain_dataset = CustomImageDataset(train_paths, train_labels, processor)\ntest_dataset = CustomImageDataset(test_paths, test_labels, processor)\n\n# Create DataLoaders for training and testing\nbatch_size = 8\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n\n# Check the class distribution in train and test sets\nfrom collections import Counter\n\ntrain_class_counts = Counter(train_labels)\ntest_class_counts = Counter(test_labels)\nprint(\"Training class distribution:\", train_class_counts)\nprint(\"Testing class distribution:\", test_class_counts)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-07T09:37:35.678939Z","iopub.execute_input":"2024-11-07T09:37:35.679368Z","iopub.status.idle":"2024-11-07T09:37:59.608031Z","shell.execute_reply.started":"2024-11-07T09:37:35.679330Z","shell.execute_reply":"2024-11-07T09:37:59.607007Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/160 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6715e2f647b14c6093e910547cd38d2b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/69.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"13e529d5a90a4e46ad0056bde7ebe61b"}},"metadata":{}},{"name":"stderr","text":"Fast image processor class <class 'transformers.models.vit.image_processing_vit_fast.ViTImageProcessorFast'> is available for this model. Using slow image processor class. To use the fast image processor class set `use_fast=True`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/347M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3e1dac0ae231468292416429cec4fe98"}},"metadata":{}},{"name":"stdout","text":"Training class distribution: Counter({7: 1272, 0: 1061, 3: 979, 1: 936, 6: 931, 2: 917, 4: 849, 5: 816, 8: 792})\nTesting class distribution: Counter({7: 318, 0: 265, 3: 245, 1: 234, 6: 233, 2: 229, 4: 213, 5: 204, 8: 198})\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom torch.optim import Adam\nfrom torch.nn import CrossEntropyLoss\nfrom tqdm import tqdm\nfrom sklearn.metrics import accuracy_score\n\n# Set device to GPU if available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)\n\n# Training hyperparameters\nepochs = 5\nlearning_rate = 1e-4\noptimizer = Adam(model.parameters(), lr=learning_rate)\ncriterion = CrossEntropyLoss()\n\n# Training loop\ndef train_model(model, train_loader):\n    model.train()  # Set the model to training mode\n    total_loss = 0\n    all_preds = []\n    all_labels = []\n    \n    for images, labels in tqdm(train_loader, desc=\"Training\"):\n        images, labels = images.to(device), labels.to(device)\n        \n        # Forward pass\n        outputs = model(images).logits\n        loss = criterion(outputs, labels)\n        \n        # Backward pass\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        # Track loss and accuracy\n        total_loss += loss.item()\n        _, preds = torch.max(outputs, 1)\n        all_preds.extend(preds.cpu().numpy())\n        all_labels.extend(labels.cpu().numpy())\n\n    epoch_loss = total_loss / len(train_loader)\n    epoch_accuracy = accuracy_score(all_labels, all_preds)\n    \n    print(f\"Training Loss: {epoch_loss:.4f}, Training Accuracy: {epoch_accuracy:.4f}\")\n\n# Evaluation loop\ndef evaluate_model(model, test_loader):\n    model.eval()  # Set the model to evaluation mode\n    all_preds = []\n    all_labels = []\n    \n    with torch.no_grad():\n        for images, labels in tqdm(test_loader, desc=\"Evaluating\"):\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images).logits\n            _, preds = torch.max(outputs, 1)\n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n\n    test_accuracy = accuracy_score(all_labels, all_preds)\n    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n    return test_accuracy\n\n# Training the model across epochs and evaluating after each epoch\nbest_accuracy = 0.0\nfor epoch in range(epochs):\n    print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n    train_model(model, train_loader)\n    test_accuracy = evaluate_model(model, test_loader)\n    \n    # Save model if it has the best accuracy\n    if test_accuracy > best_accuracy:\n        best_accuracy = test_accuracy\n        torch.save(model.state_dict(), \"best_vit_model.pth\")\n        print(\"Best model saved with accuracy:\", best_accuracy)\n\nprint(\"Training complete. Best test accuracy:\", best_accuracy)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-07T09:38:03.572218Z","iopub.execute_input":"2024-11-07T09:38:03.573275Z","iopub.status.idle":"2024-11-07T10:47:32.420260Z","shell.execute_reply.started":"2024-11-07T09:38:03.573235Z","shell.execute_reply":"2024-11-07T10:47:32.419029Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"\nEpoch 1/5\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 1070/1070 [13:13<00:00,  1.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.8783, Training Accuracy: 0.7029\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|██████████| 268/268 [01:36<00:00,  2.79it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test Accuracy: 0.9719\nBest model saved with accuracy: 0.9719495091164095\n\nEpoch 2/5\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 1070/1070 [12:12<00:00,  1.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.1050, Training Accuracy: 0.9689\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|██████████| 268/268 [01:26<00:00,  3.09it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test Accuracy: 0.9836\nBest model saved with accuracy: 0.9836372136512389\n\nEpoch 3/5\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 1070/1070 [12:12<00:00,  1.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0720, Training Accuracy: 0.9792\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|██████████| 268/268 [01:27<00:00,  3.06it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test Accuracy: 0.9659\n\nEpoch 4/5\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 1070/1070 [12:12<00:00,  1.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0748, Training Accuracy: 0.9769\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|██████████| 268/268 [01:27<00:00,  3.06it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test Accuracy: 0.9710\n\nEpoch 5/5\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 1070/1070 [12:11<00:00,  1.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0044, Training Accuracy: 0.9991\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|██████████| 268/268 [01:27<00:00,  3.06it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test Accuracy: 1.0000\nBest model saved with accuracy: 1.0\nTraining complete. Best test accuracy: 1.0\n","output_type":"stream"}]},{"cell_type":"code","source":"evaluate_model(model,test_loader)","metadata":{"execution":{"iopub.status.busy":"2024-11-07T10:59:12.961768Z","iopub.execute_input":"2024-11-07T10:59:12.962521Z","iopub.status.idle":"2024-11-07T11:00:40.019243Z","shell.execute_reply.started":"2024-11-07T10:59:12.962480Z","shell.execute_reply":"2024-11-07T11:00:40.018252Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"Evaluating: 100%|██████████| 268/268 [01:27<00:00,  3.08it/s]","output_type":"stream"},{"name":"stdout","text":"Test Accuracy: 1.0000\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"1.0"},"metadata":{}}]},{"cell_type":"code","source":"import torch\n\n# Assuming `data_loader` is your DataLoader instance\ntotal_samples = 0\nfor data, targets in test_loader:\n    total_samples += data.size(0)  # data.size(0) gives the batch size\n\nprint(f'Total number of samples: {total_samples}')\n","metadata":{"execution":{"iopub.status.busy":"2024-11-07T11:06:40.061693Z","iopub.execute_input":"2024-11-07T11:06:40.062083Z","iopub.status.idle":"2024-11-07T11:07:31.568029Z","shell.execute_reply.started":"2024-11-07T11:06:40.062047Z","shell.execute_reply":"2024-11-07T11:07:31.566964Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Total number of samples: 2139\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\n# Evaluation loop with classification report\ndef report(model, test_loader):\n    model.eval()  # Set the model to evaluation mode\n    all_preds = []\n    all_labels = []\n    \n    with torch.no_grad():\n        for images, labels in tqdm(test_loader, desc=\"Evaluating\"):\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images).logits\n            _, preds = torch.max(outputs, 1)\n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n\n    # Generate classification report\n    report = classification_report(all_labels, all_preds, target_names=class_names)\n    print(report)\n    \n    test_accuracy = accuracy_score(all_labels, all_preds)\n    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n    return test_accuracy\n\n# You can call this function after training your model to get the classification report\nreport(model, test_loader)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-07T11:09:07.758216Z","iopub.execute_input":"2024-11-07T11:09:07.758606Z","iopub.status.idle":"2024-11-07T11:10:34.551010Z","shell.execute_reply.started":"2024-11-07T11:09:07.758570Z","shell.execute_reply":"2024-11-07T11:10:34.550015Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"Evaluating: 100%|██████████| 268/268 [01:26<00:00,  3.09it/s]","output_type":"stream"},{"name":"stdout","text":"                                                precision    recall  f1-score   support\n\n                                   1Gallstones       1.00      1.00      1.00       265\n                  2Abdomen and retroperitoneum       1.00      1.00      1.00       234\n                                3cholecystitis       1.00      1.00      1.00       229\n      4Membranous and gangrenous cholecystitis       1.00      1.00      1.00       245\n                                  5Perforation       1.00      1.00      1.00       213\n              6Polyps and cholesterol crystals       1.00      1.00      1.00       204\n                              7Adenomyomatosis       1.00      1.00      1.00       233\n                                    8Carcinoma       1.00      1.00      1.00       318\n9Various causes of gallbladder wall thickening       1.00      1.00      1.00       198\n\n                                      accuracy                           1.00      2139\n                                     macro avg       1.00      1.00      1.00      2139\n                                  weighted avg       1.00      1.00      1.00      2139\n\nTest Accuracy: 1.0000\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"1.0"},"metadata":{}}]}]}